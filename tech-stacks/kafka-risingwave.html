<!DOCTYPE html>
<html lang="en">
<head>
    <title>Data Mesh Architecture: Kafka and RisingWave</title>
    <meta charset="utf-8">
    <meta name="description" content="How to build a data mesh architecture with Kafka and RisingWave" />
    <meta name="keywords" content="data mesh, data mesh architecture, domain-driven data analytics, data analytics, domain-driven design, domain ownership, data as a product, data product, federated governance, self-serve data platform, data platform, Kafka, streaming, RisingWave, streaming database">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@innoq" />
    <meta name="twitter:title" content="Data Mesh Architecture: Kafka and RisingWave" />
    <meta name="twitter:description" content="How to build a data mesh architecture with Kafka and RisingWave" />
    <meta name="twitter:image" content="https://www.datamesh-architecture.com/images/kafka-risingwave_card.webp" />
    <meta name="twitter:image:alt" content="Data Mesh Architecture: Domains are in the center and teams do analytics on their own. They build and interconnect with data products. A data platform team and a enablement team help. Global policies are agreed through federated governance." />
    <meta property="og:url" content="https://datamesh-architecture.com" />
    <meta property="og:title" content="Data Mesh Architecture: Kafka and RisingWave" />
    <meta property="og:description" content="How to build a data mesh architecture with Kafka and RisingWave" />
    <meta property="og:image" content="https://www.datamesh-architecture.com/images/kafka-risingwave_card.webp" />

    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Book.woff2?cachebuster=2" crossorigin="">
    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Bold.woff2?cachebuster=2" crossorigin="">
    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Heavy.woff2?cachebuster=2" crossorigin="">
    <link rel="stylesheet" href="../css/style.css" />
    <link rel="stylesheet" href="../css/0.9.3_css_bulma.css" />
    <link rel="stylesheet" href="../css/font-awesome_6.0.0_css_all.css"/>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
</head>
<body>
<nav class="navbar is-dark" role="navigation" aria-label="dropdown navigation">
    <div class="container">
        <div class="navbar-brand">
                    <span class="navbar-burger" data-target="navbarMenuHeroA">
            <span></span>
            <span></span>
            <span></span>
          </span>
        </div>
        <div id="navbarMenuHeroA" class="navbar-menu">

            <div class="navbar-end">


                <a href="/#why" class="navbar-item">
                    Why
                </a>
                <a href="/#what-is-data-mesh" class="navbar-item">
                    What
                </a>
                <div class="navbar-item has-dropdown is-hoverable">
                    <a href="/#how-to-design-a-data-mesh" class="navbar-link is-arrowless">
                        How
                    </a>
                    <div class="navbar-dropdown" id="navbarMenuArchitectureDropdown">
                        <a href="/#how-to-design-a-data-mesh" class="navbar-item">Data Mesh Architecture</a>
                        <hr class="navbar-divider">
                        <a href="/#data-product" class="navbar-item">Data Product</a>
                        <a href="/#federated-governance" class="navbar-item">Federated Governance</a>
                        <a href="/#analytical-data" class="navbar-item">Analytical Data</a>
                        <a href="/#ingesting" class="navbar-item">Ingesting</a>
                        <a href="/#clean-data" class="navbar-item">Clean Data</a>
                        <a href="/#analytics" class="navbar-item">Analytics</a>
                        <a href="/#data-platform" class="navbar-item">Data Platform</a>
                        <a href="/#enabling-team" class="navbar-item">Enabling Team</a>
                    </div>
                </div>
                <a href="/#mesh" class="navbar-item">
                    Mesh
                </a>
                <div class="navbar-item has-dropdown is-hoverable">
                    <div class="navbar-link is-arrowless">
                        Specifications
                    </div>
                    <div class="navbar-dropdown" id="navbarMenuSpecificationsDropdown">
                        <a href="https://www.dataproduct-specification.com" class="navbar-item">Data Product Specification</a>
                        <a href="https://www.datacontract-specification.com" class="navbar-item">Data Contract Specification</a>
                    </div>
                </div>
                <div class="navbar-item has-dropdown is-hoverable">
                    <div class="navbar-link is-arrowless">
                        Open Source
                    </div>
                    <div class="navbar-dropdown" id="navbarMenuArchitectureToolsDropdown">
                        <a href="/data-product-canvas.html" class="navbar-item">Data Product Canvas</a>
                        <a href="/fitness-test.html" class="navbar-item">Fitness Test</a><a href="/open-source/aws.html" class="navbar-item">Terraform Modules</a>
                    </div>
                </div>
                <div class="navbar-item has-dropdown is-hoverable">
                    <a href="/#tech-stacks" class="navbar-link is-arrowless">
                        Tech Stacks
                    </a>
                    <div class="navbar-dropdown" id="navbarMenuTechStackDropdown">
                        <a href="/tech-stacks/google-cloud-bigquery.html" class="navbar-item">
                            Google Cloud BigQuery
                        </a>
                        <a href="/tech-stacks/aws-s3-athena.html" class="navbar-item">
                            AWS S3 and AWS Athena
                        </a>
                        <a href="/tech-stacks/azure-synapse-analytics.html" class="navbar-item">
                            Azure Synapse Analytics
                        </a>
                        <a href="/tech-stacks/dbt-snowflake.html" class="navbar-item">
                            dbt and Snowflake
                        </a>
                        <a href="/tech-stacks/databricks.html" class="navbar-item">
                            Databricks
                        </a>
                        <a href="/tech-stacks/minio-trino.html" class="navbar-item">
                            MinIO and Trino
                        </a>
                        <a href="/tech-stacks/sap.html" class="navbar-item">
                            SAP
                        </a>
                        <a href="/tech-stacks/kafka-risingwave.html" class="navbar-item">
                            Kafka and RisingWave
                        </a>
                    </div>
                </div>
                <div class="navbar-item has-dropdown is-hoverable">
                    <a href="/#domain-teams-journey" class="navbar-link is-arrowless">
                        Start the Journey
                    </a>
                    <div class="navbar-dropdown is-right" id="navbarMenuTransformationDropdown">
                        <a href="/#domain-teams-journey" class="navbar-item">
                            Domain Team’s Journey
                        </a>
                        <a href="/#data-teams-journey" class="navbar-item">
                            Data Team’s Journey
                        </a>
                        <a href="/literature.html" class="navbar-item">
                            Scientific Literature
                        </a>
                        <a href="/real-world-learnings.html" class="navbar-item">
                            Real World Learnings
                        </a>
                        <a href="https://data-ai.innoq.com/services/data-mesh?ref=dma-nav" class="navbar-item">
                            Get Help
                        </a>
                    </div>
                </div>
                <a href="https://www.datamesh-manager.com/?ref=dma-nav" class="navbar-item" style="color: #FF9B66">
                    Data Mesh Manager
                </a>
            </div>
        </div>
    </div>
</nav>

<div class="container">

    <section class="section">

        <nav class="breadcrumb" aria-label="breadcrumbs">
            <ul>
                <li><a href="/">Data Mesh Architecture</a></li>
                <li><a href="/#tech-stacks">Tech Stacks</a></li>
                <li class="is-active"><a href="#" aria-current="page">Kafka and RisingWave</a></li>
            </ul>
        </nav>

        <h1 class="title">Kafka and RisingWave</h1>

        <div class="notification is-info is-light">
            <strong>Disclaimer</strong><br>This tech stack is unusual in style and verbosity. It describes a novel approach to Data Mesh called Streaming Data Mesh that deviates to quite some extent from the other tech stacks - and thus requires more in-depth explanations.
        </div>

        <div class="notification is-info is-light">
            Data mesh is primarily an organizational approach, and that's why you can't buy a data mesh from a vendor. Technology, however, is important still as it acts as an enabler for data mesh, and only useful and easy to use solutions will lead to domain teams' acceptance. The available offerings of cloud providers already provide a sufficient set of good self-serve data services to let you form a data platform for your data mesh. We want to show which services can be used to get started.
        </div>

        <div class="notification is-warning is-light">
            This tech stack was contributed by
            <a href="https://www.linkedin.com/in/ralph-m-debusmann-63204675/" target="_blank">
                <strong>Ralph Debusmann</strong>
                <i class="fa-solid fa-arrow-up-right-from-square"></i>
            </a>
            from Migros.
        </div>

        <div class="content">
            <h2 class="title">Introduction</h2>
            <p>
                "Classical" data mesh implementations firmly put their data products on the analytical plane, either in data warehouses (such as Snowflake or BigQuery), data lakes (S3, MinIO) or data lakehouses (Databricks). New technological advances from the streaming world, i.e., streaming databases such as Materialize and RisingWave enable us, for the first time, to depart from this pattern to keep the data products on the operational plane, in a streaming platform such as Kafka, and to pave the way for <strong>bi-directional interactions between the operational systems and data products</strong>.
            </p>
            <img src="../images/kafka-risingwave.webp" alt="Data Mesh Architecture with Kafka and RisingWave" style="width: 100%">

            <h3 class="title">Data Products Living on Kafka - Out of Reach?</h3>
            <p>
                Kafka already has its place in many "classical" implementations of data mesh, namely as an ingestion layer for streaming data into data products. This tech stack extends the scope of Kafka far beyond merely serving as an ingestion layer. Here, data products are not just ingested from Kafka but data products live on Kafka. The huge advantage of this approach is that it allows for bi-directional interactions between the operational systems and data products, i.e., data products can not only be accessed from the analytical plane, but, for the first time, also from the operational plane, in real-time. This ushers in a whole new world of real-time use cases built on such a streaming data mesh, including real-time analytics, online machine learning, customer-facing mobile apps and web apps etc., without having to build a new specialized real-time ETL pipeline for each and every data source, as would have to be done in a "classical" non-streaming data mesh implementation. Each and every of these specialized real-time ETL pipelines would, by the way, have to bypass the data mesh and would thus strongly violate the very tenets of its underlying principles.
            </p>

            <p>
                So far, practical implementations of a streaming data mesh have been out of reach. Especially the following three challenges posed insurmountable hurdles for such an implementation pattern:
                <ol>
                    <li>The complexity of stream processing systems such as Flink and Kafka Streams for data processing "on the stream". It was hardly possible to do non-trivial stream processing without having to do in-depth JVM coding (e.g. Java, Kotlin, Scala) and possessing in-depth streaming expertise.</li>
                    <li>The inability of these stream processing systems to deliver a database-like experience. Database experts would be forced to re-think a lot of what they knew when they would switch over from "data-at-rest" (databases) to "data-in-motion" (streaming) - so much that few of them have ever considered it.</li>
                    <li>Even though Kafka is able to serve both streaming/real-time and batch/non-realtime use cases, reading from Kafka in a batch/non-real-time setting required complex and cost-intensive coding or the set up of additional infrastructure.</li>
                </ol>
            </p>

            <h3 class="title">Streaming Databases - A Game Changer</h3>
            <p>
                Thankfully, a new technological development in the streaming field has brought these previously insurmountable hurdles to a fall and acts as a game changer: Streaming databases. This is why:
                <ol>
                    <li>Streaming databases support complex SQL-based stream processing like a normal database, with nested deeply JOINs, self-JOINs etc.</li>
                    <li>Streaming databases deliver a database-like experience with consistency guarantees such as snapshot isolation and atomicity, which are not (yet?) fully available in older stream processing systems. Materialize and RisingWave even have a PostgreSQL wire-compatible interface, which not only makes them easy to adopt by anybody with database expertise, but also allows them to be used in conjunction with tools such as dbt.</li>
                    <li>Streaming databases provide incrementally maintained Materialized Views which can be queried like in a normal database. This enables the seamless use of real-time streaming data in a batch/non-real-time setting, i.e., if the latest data only has to be read once a day or even once a week.</li>
                </ol>
            </p>

            <h3 class="title">Vendors - Open Source and Commercial</h3>
            <p>
                This tech stack is, at its heart, based purely on Open Source: It includes only Open Source software. This is also why it choses RisingWave instead of Materialize as the streaming database - it is Open Source whereas Materialize is not. It should be noted that Materialize was the first streaming database of this kind (2020), whereas RisingWave came out later (2022).
            </p>

            <p>
                Notable commercial vendors for Kafka are: Confluent (founded by the original developers of Apache Kafka), AWS MSK, Aiven, Instaclustr and Redpanda. All of them offer (cloud-)hosted Kafka plus a plethora of additional features on top the Open Source Apache Kafka. Materialize and RisingWave also offer cloud-hosted products - so for both central architectural parts of this tech stack, you can easily switch away from self-hosting.
            </p>

            <h2 class="title">Individual Components of this Tech Stack</h2>

            <h3 class="title">Self-serve Data Platform</h3>
            <p>
                Let's dive into the individual components of this tech stack/architectural blueprint. In the main diagram above, let's first have a look at the Self-serve Data Platform (bottom). This tech stack suggests to use e.g. popular Open Source tools like OpenIAM and Keycloak for Access Management (second from left in the main diagram), and Grafana and ArgoCD for Platform Operations (right-hand side), where ArgoCD is a Continuous Deployment (CD) tool on top of Kubernetes.
            </p>

            <div class="columns">
                <div class="column">
                    <h3 class="title">Operational Data</h3>
                    <p>
                        We continue with the Operational Data box (left-hand side of the middle circle). Here, the data typically comes from Kafka (in the form of messages, like the ones in the screenshot from Confluent Cloud to the right), or from (operational) databases.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <img src="../images/kafka.webp" alt="Screenshot of Apache Kafka">
                    </figure>
                </div>
            </div>
            <div class="columns">
                <div class="column">
                    <h3 class="title">Data Product</h3>
                    <p>
                        In the Data Product box (in the middle of the middle circle in the main diagram), you can see the most drastic change in comparison to most other existing data mesh implementations. Here, this tech stack employs two streaming systems, Kafka and RisingWave (see RisingWave screenshot to the right), instead of using a data warehouse such as Snowflake or a data lake such as S3. The purpose of this is to keep all the data "in-motion", rather than putting them "at rest", enabling data products to flow back to the operational plane. For instance, customer transactions from the operational ERP system can be combined with customer information from the CRM system to create a "streaming data product" which can directly be read, in real-time, from a customer-facing mobile app.
                    </p>

                    <p>
                        Using RisingWave combined with dbt, you can build CI/CD pipelines around SQL-based stream processing pipelines to create new, filtered, transformed and/or joined streams on Kafka. It is best practice to write all data to Kafka first to have a unified, single source of truth for the data, and use RisingWave for stream processing and for serving Materialized Views.
                    </p>

                </div>
                <div class="column">
                    <figure class="image">
                        <img src="../images/risingwave.webp" alt="Screenshot of RisingWave">
                    </figure>
                </div>
            </div>
            <div class="columns">
                <div class="column">
                    <h3 class="title">Data Contract</h3>
                    <p>
                        In the Data Contract box (right of the middle circle of the main diagram), you can see that all the datasets are held in Kafka. This tech stack uses a Schema Registry (e.g. the Open Source tool "Karapace") to define data products (in particular, their schemas) in conjunction with a Data Catalog tool (first left in Self-serve Data Platform) such as DataHub (see screenshot to the right) or dbt-docs.
                    </p>

                    <p>
                        This tech stack uses Kafka on three layers: Operational Data, Data Product and Data Contract. Does this mean we have to duplicate our data three times? No. On the contrary it is best practice to use organization-wide central Kafka clusters spanning all three layers. These Kafka clusters hold operational data, data products (e.g. combined from various other data products) and datasets at same time, making use of the extreme scalability and high availability of Kafka. NB: Not all data on Kafka automatically qualifies as a data product. Data products on Kafka are distinguished from non-data product data by namespacing and Access Control Lists (ACLs).
                    </p>

                </div>
                <div class="column">
                    <figure class="image">
                        <img src="../images/datahub.webp" alt="Screenshot of DataHub">
                    </figure>
                </div>
            </div>
            <div class="columns">
                <div class="column">
                    <h3 class="title">Analytics</h3>
                    <p>
                        In the Analytics box (at the top of the main diagram), this tech stack first proposes the use of a real-time analytics database (sometimes called "real-time OLAP database" or "RTOLAP") for use cases with low-latency requirements. This enables real-time analytics on fresh data products directly from Kafka. Among the most popular Open Source real-time analytics databases are Apache Pinot (vendors: StarTree, ...; see screenshot to the right), Apache Druid (vendors: Imply, ...) and Clickhouse (vendors: Clickhouse, Aiven...). In addition, Python tooling and Jupyter notebooks can be combined with real-time analytics databases for code-based analytics and online machine learning.
                    </p>

                </div>
                <div class="column">
                    <figure class="image">
                        <img src="../images/pinot.webp" alt="Screenshot of Apache Pinot">
                    </figure>
                </div>
            </div>
            <div class="columns">
                <div class="column">
                    <p>
                        As for the data warehouse in the Analytics box, this tech stack proposes the use of an Open Source data warehouse such as DuckDB (vendor: Motherduck; see screenshot on the right) or Apache Hive. Of course, commercial solutions like Snowflake, Databricks etc. could also be employed here. The role of these tools is to do serve and complex non-real-time analytics requirements which cannot be fully addressed by the real-time analytics databases above. Real-time analytics databases are primarily optimized for performance, concurrency (thousands of queries per second) and data freshness, but have to compromise on their support for ad-hoc and/or arbitrarily complex queries. As for the real-time analytics above, this architecture blueprint proposes Jupyter notebooks for code-based (non-real-time) analytics and batch machine learning.
                    </p>

                </div>
                <div class="column">
                    <figure class="image">
                        <img src="../images/duckdb.webp" alt="Screenshot of DuckDB">
                    </figure>
                </div>
            </div>
            <div class="columns">
                <div class="column">
                    <p>
                        We close the explanation of the Analytics box with data visualization. Here, this tech stack suggests the use of Open Source visualization tools such as Apache Superset (see screenshot on the right), Redash, or Python-based visualization tools like Streamlit.
                    </p>

                </div>
                <div class="column">
                    <figure class="image">
                        <img src="../images/superset.webp" alt="Screenshot of Apache Superset">
                    </figure>
                </div>
            </div>

            <h5>References</h5>
            <ul>
                <li><a href="https://kafka.apache.org/">Apache Kafka (homepage)</a></li>
                <li><a href="https:/risingwave.dev/">RisingWave (homepage)</a></li>
                <li><a href="https://risingwave.com/blog/why-kafka-is-the-new-data-lake/">Why Kafka Is the New Data Lake (Blog/RisingWave)</a></li>
                <li><a href="https://risingwave.com/blog/streaming-databases-everything-you-wanted-to-know/">Streaming Databases: Everything You Wanted to Know</a></li>
                <li><a href="https://materialize.com/blog/operational-data-warehouse/">Materialize: An Operational Data Warehouse (Blog/Materialize)</a></li>
                <li><a href="https://www.oreilly.com/library/view/streaming-data-mesh/9781098130718/">Streaming Data Mesh (book by Hubert Dulay and Stephen Mooney)</a></li>
                <li><a href="https://www.confluent.io/resources/ebook/data-mesh-architectures-with-event-streams-v2/">Build a Data Mesh with Event Streams (book by Adam Bellemare)</a></li>
                <li><a href="https://www.oreilly.com/library/view/streaming-databases/9781098154820/">Streaming Databases (upcoming book by Hubert Dulay and Ralph Debusmann)</a></li>
            </ul>

        </div>
    </section>

</div>

<footer class="footer">
    <div class="content has-text-centered">
        <p>
            <a href="https://www.innoq.com">
                <img src="/images/supported-by-innoq--petrol-apricot.svg" alt="Supported by INNOQ" class="footer-logo" width="180" />
            </a>
        </p>
        <p>
            <a href="https://www.innoq.com/en/topics/data-mesh-workshop?ref=dma-footer">Workshop</a>&nbsp
            <a href="https://www.socreatory.com/de/trainings/datamesh?ref=dma-footer">Training</a>&nbsp
            <a href="https://www.innoq.com/en/impressum/">Legal Notice</a>&nbsp
            <a href="https://www.innoq.com/en/datenschutz/">Privacy</a>
        </p>
    </div>
</footer>


<script src="/js/navigation.js"></script>

<script async defer src="https://scripts.simpleanalyticscdn.com/latest.js"></script>
<noscript><img src="https://queue.simpleanalyticscdn.com/noscript.gif" alt="" referrerpolicy="no-referrer-when-downgrade" /></noscript>

<link rel="stylesheet" href="/css/glightbox.css" />
<script src="/js/glightbox.js"></script>
<script type="text/javascript">
  const lightbox = GLightbox({});
</script>


<script src="/js/anchor.min.js"></script>
<script>anchors.add();</script>
</body>

</html>
