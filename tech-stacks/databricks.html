<!DOCTYPE html>
<html lang="en">
<head>
    <title>Data Mesh Architecture: Databricks</title>
    <meta charset="utf-8">
    <meta name="description" content="How to build a data mesh architecture with Databricks" />
    <meta name="keywords" content="data mesh, data mesh architecture, domain-driven data analytics, data analytics, domain-driven design, domain ownership, data as a product, data product, federated governance, self-serve data platform, data platform">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@innoq" />
    <meta name="twitter:title" content="Data Mesh Architecture: Databricks" />
    <meta name="twitter:description" content="How to build a data mesh architecture with Databricks" />
    <meta name="twitter:image" content="https://www.datamesh-architecture.com/images/databricks_card.png" />
    <meta name="twitter:image:alt" content="Data Mesh Architecture: Domains are in the center and teams do analytics on their own. They build and interconnect with data products. A data platform team and a enablement team help. Global policies are agreed through federated governance." />
    <meta property="og:url" content="https://datamesh-architecture.com" />
    <meta property="og:title" content="Data Mesh Architecture: Databricks" />
    <meta property="og:description" content="How to build a data mesh architecture with Databricks" />
    <meta property="og:image" content="https://www.datamesh-architecture.com/images/databricks_card.png" />

    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Book.woff2?cachebuster=2" crossorigin="">
    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Bold.woff2?cachebuster=2" crossorigin="">
    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Heavy.woff2?cachebuster=2" crossorigin="">
    <link rel="stylesheet" href="../css/style.css" />
    <link rel="stylesheet" href="../css/0.9.3_css_bulma.css" />
    <link rel="stylesheet" href="../css/font-awesome_6.0.0_css_all.css"/>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
</head>
<body>
<nav class="navbar is-dark" role="navigation" aria-label="dropdown navigation">
    <div class="container">
        <div class="navbar-brand">
                    <span class="navbar-burger" data-target="navbarMenuHeroA">
            <span></span>
            <span></span>
            <span></span>
          </span>
        </div>
        <div id="navbarMenuHeroA" class="navbar-menu">

            <div class="navbar-end">


                <a href="/#why" class="navbar-item">
                    Why
                </a>
                <a href="/#what-is-data-mesh" class="navbar-item">
                    What
                </a>
                <div class="navbar-item has-dropdown is-hoverable">
                    <a href="/#how-to-design-a-data-mesh" class="navbar-link is-arrowless">
                        How
                    </a>
                    <div class="navbar-dropdown" id="navbarMenuArchitectureDropdown">
                        <a href="/#how-to-design-a-data-mesh" class="navbar-item">Data Mesh Architecture</a>
                        <hr class="navbar-divider">
                        <a href="/#data-product" class="navbar-item">Data Product</a>
                        <a href="/#federated-governance" class="navbar-item">Federated Governance</a>
                        <a href="/#analytical-data" class="navbar-item">Analytical Data</a>
                        <a href="/#ingesting" class="navbar-item">Ingesting</a>
                        <a href="/#clean-data" class="navbar-item">Clean Data</a>
                        <a href="/#analytics" class="navbar-item">Analytics</a>
                        <a href="/#data-platform" class="navbar-item">Data Platform</a>
                        <a href="/#enabling-team" class="navbar-item">Enabling Team</a>
                    </div>
                </div>
                <a href="/#mesh" class="navbar-item">
                    Mesh
                </a>
                <div class="navbar-item has-dropdown is-hoverable">
                    <div class="navbar-link is-arrowless">
                        Tools
                    </div>
                    <div class="navbar-dropdown" id="navbarMenuArchitectureToolsDropdown">
                        <a href="/data-product-canvas.html" class="navbar-item">Data Product Canvas</a>
                        <a href="/self-assessment.html" class="navbar-item">Self Assessment</a>
                    </div>
                </div>
                <div class="navbar-item has-dropdown is-hoverable">
                    <a href="/#tech-stacks" class="navbar-link is-arrowless">
                        Tech Stacks
                    </a>
                    <div class="navbar-dropdown" id="navbarMenuTechStackDropdown">
                        <a href="/tech-stacks/google-cloud-bigquery.html" class="navbar-item">
                            Google Cloud BigQuery
                        </a>
                        <a href="/tech-stacks/aws-s3-athena.html" class="navbar-item">
                            AWS S3 and AWS Athena
                        </a>
                        <a href="/tech-stacks/azure-synapse-analytics.html" class="navbar-item">
                            Azure Synapse Analytics
                        </a>
                        <a href="/tech-stacks/dbt-snowflake.html" class="navbar-item">
                            dbt and Snowflake
                        </a>
                        <a href="/tech-stacks/databricks.html" class="navbar-item">
                            Databricks
                        </a>
                    </div>
                </div>
                <div class="navbar-item has-dropdown is-hoverable">
                    <a href="/#domain-teams-journey" class="navbar-link is-arrowless">
                        Start the Journey
                    </a>
                    <div class="navbar-dropdown is-right" id="navbarMenuTransformationDropdown">
                        <a href="/#domain-teams-journey" class="navbar-item">
                            Domain Team’s Journey
                        </a>
                        <a href="/#data-teams-journey" class="navbar-item">
                            Data Team’s Journey
                        </a>
                        <a href="/real-world-learnings.html" class="navbar-item">
                            Real World Learnings
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</nav>

<div class="container">

    <section class="section">

        <nav class="breadcrumb" aria-label="breadcrumbs">
            <ul>
                <li><a href="/">Data Mesh Architecture</a></li>
                <li><a href="/#tech-stacks">Tech Stacks</a></li>
                <li class="is-active"><a href="#" aria-current="page">Databricks</a></li>
            </ul>
        </nav>

        <h1 class="title">Databricks</h1>

        <div class="notification is-info is-light">
            Data mesh is primarily an organizational approach, and that's why you can't buy a data mesh from a vendor. Technology, however, is important still as it acts as an enabler for data mesh, and only useful and easy to use solutions will lead to domain teams' acceptance. The available offerings of cloud providers already provide a sufficient set of good self-serve data services to let you form a data platform for your data mesh. We want to show which services can be used to get started.
        </div>

        <div class="content">
            <p>
                The Databricks Lakehouse Platform is a popular data platform.
                It is fully based on <em>Apache Spark</em>.
                In fact, the people who created Apache Spark found the company to offer a commercial data platform.
                In addition, they heavily promote <em>Delta Lake</em>, a storage format for files that uses versioned Parquet files and a transaction log to provide ACID transactions.
            </p>
            <p>
                Databricks is a full-featured platform that runs on top of one of the three cloud providers: AWS, GCP, Azure.
                On Azure, Microsoft is your business partner, so you don't have to sign a separate contract with Databricks.
                In any case, the cloud provider resources (such as object storage, compute engines, virtual network configuration, access control) are used by the platform.
                The platform basically runs in compute engines and uses futher compute engines to manage workloads.
            </p>
            <p>
                Databricks is very popular among Data Scientists.
                It has an integrated environment, collaborative notebooks, and managed and scalable resources.
                But is it also a good choice for a general Data Mesh platform?
                Let's dive into the components that we would use for Data Mesh.
            </p>
            <img src="../images/databricks.png.webp" alt="Data Mesh Architecture with Databricks" style="width: 100%">

            <div class="columns">
                <div class="column">
                    <p>
                        The starting point in Databricks is the <strong>workspace</strong>.
                        Each team typically creates their own workspace,
                        and in their workspace their own <strong>clusters</strong> for their computing needs.
                        These clusters come with a configured <em>Spark Runtime</em> as query engine.
                        The clusters are mapped to cloud provider's compute instances and
                        can be scaled elastically with the workloads to execute code and queries.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/databricks_cluster.png" class="glightbox">
                            <img src="../images/databricks_cluster.png" alt="Databricks requires a Spark cluster to run code.">
                        </a>
                    </figure>
                </div>
            </div>

            <div class="columns">
                <div class="column">
                    <p>
                        Data are always stored as files.
                        To ingest data, data need to be written to an object store (S3, Cloud Storage, ADLS) by a provider in an appropriate format, such as Parquet, JSON, CSV or Delta.
                        Transformed and intermediary data are usually written to <strong>delta files</strong> in a backing object storage, but Spark supports all other formats, if required.
                        Delta files represent a table structure, and are optimized for columnar access.
                        These delta tables also support insert, update and delete operations.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/databricks_files.png" class="glightbox">
                            <img src="../images/databricks_files.png" alt="Databricks relies on files on the object store">
                        </a>
                    </figure>
                </div>
            </div>

            <div class="columns">
                <div class="column">
                    <p>
                        With Spark, most of the data engineering is typically coded in Jupyter-like <strong>notebooks</strong> using <em>Python</em>, <em>Scala</em>, or <em>Spark SQL</em> code.
                        The notebooks are interactive, meaning that cells can be executed directly and iteratively.
                        With Databricks, data import, cleaning, transformation, explorative analytics, and machine learning is coded in notebooks.
                        The code can usually be managed in a connected Git repository.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/databricks_notebook.png" class="glightbox">
                            <img src="../images/databricks_notebook.png" alt="A Notebook in Databricks contains code">
                        </a>
                    </figure>
                </div>
            </div>

            <div class="columns">
                <div class="column">
                    <p>
                        Notebooks are also the default way to build <strong>data products</strong>.
                        <em>Delta live tables</em> are used to build managed pipelines with notebooks, for scheduled or continuous tranformations.
                        Notebooks include the code that imports data, transforms and aggregates, performs validation, includes tests and quality metrics and finally creates a data set in the export format.
                        Through Spark, there is a lot of freedom how to operate with the data and available libraries (especially for Python) provide unlimited capabilities.
                        For example, a data product notebook may also include a step to generate and publish a data product description for documentation, including dynamic information on the current data set.
                        Also, <strong>policy automation</strong> can be implemented this way, e.g. by including a shared library that performs anonymization procedures on tagged columns.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/databricks_dlt.png" class="glightbox">
                            <img src="../images/databricks_dlt.png" alt="Delta live tables can be used as managed pipelines">
                        </a>
                    </figure>
                </div>
            </div>

            <div class="columns">
                <div class="column">
                    <p>
                        A <strong>metastore</strong> maps table structures to underlying files in the object store.
                        This allows you to execute structured SQL queries to files and to evolve the schema over time.
                        Traditionally, most Data Lakes rely on Apache Hive, a metastore coming from Hadoop.
                        As Hive has some drawbacks (e.g., difficult to install and maintain, requires a relational database).
                        Databricks recently implemented an alternative to Hive, the <em>Unity Catalog</em>, a proprietary metastore for Databricks.
                        A Unity Catalog can be shared across workspaces, as it is backed by a simple object store.
                    </p>
                    <p>
                        All tables and columns are registered in the metastore.
                        This makes the metastore a candidate for a <strong>data catalog</strong> to publish, manage and discover data products.
                        A frequent challenge with a metastore as a data catalog is that it quickly becomes clattered and convoluted with internal and irrelevant data structures, important data products may perish.
                        Unity Catalog is quite new, but certainly will become the default data catalog solution for a Databricks-only data platform concept.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/databricks_catalog.png" class="glightbox">
                            <img src="../images/databricks_catalog.png" alt="">
                        </a>
                    </figure>
                </div>
            </div>

            <div class="columns">
                <div class="column">
                    <p>
                        Databricks Premium comes with special view for data analysts that prefer to work with SQL.
                        Historically, it was just an SQL endpoint to access data on Databricks, but additional services were added, providing a more data-warehouse-like experience.
                        SQL features can be used for data mesh capabilities:
                        Software engineers can use SQL for simple analytics, without the need to work with notebooks, and they can leverage <em>SQL dashboards</em> and visualizations to gain <strong>insights</strong>.
                        <em>SQL alerts</em> can be used for basic <strong>data quality monitoring</strong>, as they run queries regularly and send notifications to a when the queries trigger.
                        The SQL warehouse provides an HTTP or JDBC <em>connection endpoint</em> to publish data products for external applications, such as Tableau or PowerBI.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/databricks_sql.png" class="glightbox">
                            <img src="../images/databricks_sql.png" alt="SQl queries with Databricks">
                        </a>
                    </figure>
                </div>
            </div>

            <p>
                Databricks is probably the most powerful data platform available today, and it clearly can act as a foundation for a data mesh platform.
                It is optimized for data scientists that work a lot with notebooks, but it also
                invested in further experiences.
                As it tightly interacts with the cloud provider for data storage and access management, organization and administration will take a while to master for the data platform team, and it must be set up appropriately from the beginning.
                Databricks is a great platform for data analysts and machine learning, but the entry barrier is pretty high for occasional users.
                Domain team's software engineers who use data analytics from time to time and build just a few data products,
                may need a lot of guidance by an enabling team to work efficiently and to gain a positive developer experience.<br>
            </p>

            <h5>References</h5>
            <ul>
                <li><a href="https://docs.databricks.com/">Official databricks documentation</a></li>
                <li><a href="https://www.youtube.com/watch?v=a00rdlNtW98">Data Mesh and Data Lakehouse talk by co-founder of Databricks</a></li>
            </ul>

        </div>
    </section>

</div>

<footer class="footer">
    <div class="content has-text-centered">
        <p>
            <a href="https://www.innoq.com">
                <img src="/images/supported-by-innoq--petrol-apricot.svg" alt="Supported by INNOQ" class="footer-logo" width="180" />
            </a>
        </p>
        <p>
            <a href="https://www.innoq.com/en/topics/data-mesh-workshop?ref=dma-footer">Workshop</a>&nbsp
            <a href="https://www.socreatory.com/de/trainings/datamesh?ref=dma-footer">Training</a>&nbsp
            <a href="https://www.innoq.com/en/impressum/">Legal Notice</a>&nbsp
            <a href="https://www.innoq.com/en/datenschutz/">Privacy</a>
        </p>
    </div>
</footer>


<script src="/js/navigation.js"></script>

<script async defer src="https://scripts.simpleanalyticscdn.com/latest.js"></script>
<noscript><img src="https://queue.simpleanalyticscdn.com/noscript.gif" alt="" referrerpolicy="no-referrer-when-downgrade" /></noscript>

<link rel="stylesheet" href="/css/glightbox.css" />
<script src="/js/glightbox.js"></script>
<script type="text/javascript">
  const lightbox = GLightbox({});
</script>


<script src="/js/anchor.min.js"></script>
<script>anchors.add();</script>
</body>

</html>
