<!DOCTYPE html>
<html lang="en">
<head>
    <title>Data Mesh Architecture: MinIO and Trino</title>
    <meta charset="utf-8">
    <meta name="description" content="How to build a data mesh architecture with MinIO and Trino" />
    <meta name="keywords" content="data mesh, data mesh architecture, domain-driven data analytics, data analytics, domain-driven design, domain ownership, data as a product, data product, federated governance, self-serve data platform, data platform">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="twitter:card" content="summary_large_image" />
    <meta name="twitter:site" content="@innoq" />
    <meta name="twitter:title" content="Data Mesh Architecture: MinIO and Trino" />
    <meta name="twitter:description" content="How to build a data mesh architecture with MinIO and Trino" />
    <meta name="twitter:image" content="https://www.datamesh-architecture.com/images/minio-trino_card.png" />
    <meta name="twitter:image:alt" content="Data Mesh Architecture: Domains are in the center and teams do analytics on their own. They build and interconnect with data products. A data platform team and a enablement team help. Global policies are agreed through federated governance." />
    <meta property="og:url" content="https://datamesh-architecture.com" />
    <meta property="og:title" content="Data Mesh Architecture: MinIO and Trino" />
    <meta property="og:description" content="How to build a data mesh architecture with MinIO and Trino" />
    <meta property="og:image" content="https://www.datamesh-architecture.com/images/minio-trino_card.png" />

    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Book.woff2?cachebuster=2" crossorigin="">
    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Bold.woff2?cachebuster=2" crossorigin="">
    <link rel="preload" as="font" type="font/woff2" href="https://www.innoq.com/assets/MarkPro-Heavy.woff2?cachebuster=2" crossorigin="">
    <link rel="stylesheet" href="../css/style.css" />
    <link rel="stylesheet" href="../css/0.9.3_css_bulma.css" />
    <link rel="stylesheet" href="../css/font-awesome_6.0.0_css_all.css"/>
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico">
</head>
<body>
<nav class="navbar is-dark" role="navigation" aria-label="dropdown navigation">
    <div class="container">
        <div class="navbar-brand">
                    <span class="navbar-burger" data-target="navbarMenuHeroA">
            <span></span>
            <span></span>
            <span></span>
          </span>
        </div>
        <div id="navbarMenuHeroA" class="navbar-menu">

            <div class="navbar-end">


                <a href="/#why" class="navbar-item">
                    Why
                </a>
                <a href="/#what-is-data-mesh" class="navbar-item">
                    What
                </a>
                <div class="navbar-item has-dropdown is-hoverable">
                    <a href="/#how-to-design-a-data-mesh" class="navbar-link is-arrowless">
                        How
                    </a>
                    <div class="navbar-dropdown" id="navbarMenuArchitectureDropdown">
                        <a href="/#how-to-design-a-data-mesh" class="navbar-item">Data Mesh Architecture</a>
                        <hr class="navbar-divider">
                        <a href="/#data-product" class="navbar-item">Data Product</a>
                        <a href="/#federated-governance" class="navbar-item">Federated Governance</a>
                        <a href="/#analytical-data" class="navbar-item">Analytical Data</a>
                        <a href="/#ingesting" class="navbar-item">Ingesting</a>
                        <a href="/#clean-data" class="navbar-item">Clean Data</a>
                        <a href="/#analytics" class="navbar-item">Analytics</a>
                        <a href="/#data-platform" class="navbar-item">Data Platform</a>
                        <a href="/#enabling-team" class="navbar-item">Enabling Team</a>
                    </div>
                </div>
                <a href="/#mesh" class="navbar-item">
                    Mesh
                </a>
                <div class="navbar-item has-dropdown is-hoverable">
                    <a href="/#tech-stacks" class="navbar-link is-arrowless">
                        Tech Stacks
                    </a>
                    <div class="navbar-dropdown" id="navbarMenuTechStackDropdown">
                        <a href="/tech-stacks/google-cloud-bigquery.html" class="navbar-item">
                            Google Cloud BigQuery
                        </a>
                        <a href="/tech-stacks/aws-s3-athena.html" class="navbar-item">
                            AWS S3 and AWS Athena
                        </a>
                        <a href="/tech-stacks/azure-synapse-analytics.html" class="navbar-item">
                            Azure Synapse Analytics
                        </a>
                        <a href="/tech-stacks/dbt-snowflake.html" class="navbar-item">
                            dbt and Snowflake
                        </a>
                        <a href="/tech-stacks/databricks.html" class="navbar-item">
                            Databricks
                        </a>
                        <a href="/tech-stacks/minio-trino.html" class="navbar-item">
                            MinIO and Trino
                        </a>
                    </div>
                </div>
                <div class="navbar-item has-dropdown is-hoverable">
                    <a href="/#domain-teams-journey" class="navbar-link is-arrowless">
                        Start the Journey
                    </a>
                    <div class="navbar-dropdown is-right" id="navbarMenuTransformationDropdown">
                        <a href="/#domain-teams-journey" class="navbar-item">
                            Domain Team’s Journey
                        </a>
                        <a href="/#data-teams-journey" class="navbar-item">
                            Data Team’s Journey
                        </a>
                        <a href="/real-world-learnings.html" class="navbar-item">
                            Real World Learnings
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</nav>

<div class="container">

    <section class="section">

        <nav class="breadcrumb" aria-label="breadcrumbs">
            <ul>
                <li><a href="/">Data Mesh Architecture</a></li>
                <li><a href="/#tech-stacks">Tech Stacks</a></li>
                <li class="is-active"><a href="#" aria-current="page">MinIO and Trino</a></li>
            </ul>
        </nav>

        <h1 class="title">MinIO and Trino</h1>

        <div class="notification is-info is-light">
            Data mesh is primarily an organizational approach, and that's why you can't buy a data mesh from a vendor. Technology, however, is important still as it acts as an enabler for data mesh, and only useful and easy to use solutions will lead to domain teams' acceptance. The available offerings of cloud providers already provide a sufficient set of good self-serve data services to let you form a data platform for your data mesh. We want to show which services can be used to get started.
        </div>

        <div class="content">
            <p>
                For local development and PoCs we often use a tech stack based on Trino for query processing and Minio for storage using columnar file formats like Parquet or open table formats like Iceberg.
                We believe, that this tech stack can also be used for production environments, where the offerings of vendors like Databricks or Snowflake are considered too costly.
                This tech stack can easily be enhanced with tools like jupyter notebooks for data exploration and processing, dbt for enhanced automated data transformation, LakeFS for data versioning or Marquez for data lineage support.
                <br/>
            </p>
            
            <img src="../images/lakefs_trino.webp" alt="Data Mesh Architecture with LakeFS and Trino" style="width: 100%">

            <!-- Ease of deployment -->
            <div class="columns">
                <div class="column">
                    <p>
                        <!-- deployment options: kubernetes or pandio + jupyterHub + elestio -->
                        This tech stack is lightweight, which we deployed locally using docker-compose.
                        For production deployment that local setup could be transferred via kubernetes as a managed service. This should be quite straightforward, but it hasn't been done by us, yet.
                        Another deployment option would be using separate managed services like Pandio for Trino, Elestio for MinIO and JupyterHub for the notebooks.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/lakeFS_dockercontainers.png" class="glightbox">
                            <img src="../images/lakeFS_dockercontainers.png" alt="Docker container overview">
                        </a>
                    </figure>
                </div>
            </div>

            <!-- S3 compatible object storage - file system structure provided by lakefs -->
            <div class="columns">
                <div class="column">
                    <p>
                        <a href="https://min.io">MinIO</a> provides simple and high-performance object storage with a wide variety of deployment options. Thereby the MinIO object
                        storage can be backed up by any <strong>s3-compatible object storage</strong>.
                        <!-- MinIO provides a now community driven <strong>Azure Gateway</strong>, which allows to connect to the non-s3-compatible storage Azure Data Lake Gen 1. -->
                    </p>
                    <p>
                        We typically use <a href="https://lakefs.io">LakeFS</a> as an independent hierarchical file system on top of the underlying object storage.
                        A benefit of lakeFS is the git-like data versioning support, which we will come back to in a later section.
                    </p>
                </div>
                <!-- noch ein lakeFS filesystem bild dazu ? -->
                <div class="column">
                    <figure class="image">
                        <a href="../images/lakeFS_minio_homescreen.png" class="glightbox">
                            <img src="../images/lakeFS_minio_homescreen.png" alt="MinIO Demoscreen">
                        </a>
                    </figure>
                </div>
            </div>

            <!-- trino allows sql based access on the data based storage -->
            <div class="columns">
                <div class="column">
                    <p>
                        <a href="https://trino.io">Trino</a> is a distributed, highly scalable query engine, that allows to access and manipulate data from <strong>various storage systems</strong>.
                        Trino therefore currently relies on a Hive metastore to support SQL based access to data files stored in object storage systems.
                    </p>
                    <!-- Ease of migration from existing SQL based data processing -->
                    <p>
                        Trino comes with the ability to combine tables from multiple sources in one sql statement.
                        This gives an easy migration for already existing applications.
                        For example, if the old database solution is compatible with trino, it can simply be transferred for the new solution or even be integrated into the data mesh.
                        Additionally, this makes the connection to source systems much easier.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/lakeFS_DBeaver_homescreen.png" class="glightbox">
                            <img src="../images/lakeFS_DBeaver_homescreen.png" alt="Any DB picture">
                        </a>
                    </figure>
                </div>
            </div>

            <!-- data exploration with trino and jupyter notebooks -->
            <div class="columns">
                <div class="column">
                    <p>
                        The data exploration can be done directly using the SQL data access provided by trino.
                        <br/>
                        Therefore, combining jupyter notebooks with trino results in a <strong>powerful and flexible IDE for exploratory analysis</strong> using an ecosystem like python together with SQL processing.
                    </p>

                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/lakeFS_trino_query.png" class="glightbox">
                            <img src="../images/lakeFS_trino_query.png" alt="Jupyter notebook demo query">
                        </a>
                    </figure>
                </div>
            </div>

            <!-- Using trino tables/sets of tables as data products -->
            <div class="columns">
                <div class="column">
                    <p>
                        In a data mesh, every domain team provides access to their data by the use of <strong>data products</strong>. A data product can be defined as a single or a combined set of SQL tables.
                        <br/>
                        We typically use one lakeFS repository for all data products of a domain team. All of these data products are accessible through the same SQL schema.
                        <br/>
                        All data files holding the data of a data product are stored in a separate directory tree in our lakeFS file system.
                        With trino, <strong>data products from different domains</strong> can be easily combined by using standard SQL joins.
                    </p>
                    <p>
                        To <strong>design a data product</strong>, we suggest a workflow that starts with the data exploration in jupyter notebooks.
                        When the data exploration results in useful analytical data, the necessary data processing steps can be implemented and quality approved using jupyter notebooks.
                        <br/>
                        Alternatively, an additional tool like <a href="https://www.getdbt.com/">dbt</a> can be used for this, as it makes the implementation and maintenance of data products easier.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/lakefs_data_product_example.png" class="glightbox">
                            <img src="../images/lakefs_data_product_example.png" alt="data product bild">
                        </a>
                    </figure>
                </div>
            </div>

            <!-- data versioning with lakefs -->
            <div class="columns">
                <div class="column">
                    <p>
                        <a href="https://lakefs.io">LakeFS</a> is a git-like data versioning tool that recently has emerged high popularity.
                        Thereby <strong>lakeFS provides data versioning</strong> for the data in the underlying object store.
                        lakeFS branches support the creation of isolated snapshots of data. The data provided through a version of a data product could be stored on a specific branch.
                        <br/>
                        The benefit is that in this process the underlying <strong>data files are not actually copied</strong> for the creation of this branch, which can save a lot of storage space.
                    </p>
                    <p>
                        Moreover, branches make the data exploration or testing easier by reducing the risk of loosing or corrupting valuable production data.
                        If something goes wrong, the affected branch can just be deleted or reverted to an older state.
                        <br/>
                        <!-- formulierung ? -->
                        So, branches provide the ability to <strong>time travel</strong> between successive versions of a data product.
                        With that, the lakeFS data versioning support can also be helpful to better cope with the eventual consistency of the underlying object storage.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/lakefs_branches_list.png" class="glightbox">
                            <img src="../images/lakefs_branches_list.png" alt="Lakefs branches picture">
                        </a>
                    </figure>
                </div>
            </div>

            <!-- organization =
                    Cloud provider - lakefs instance - mehrere Repos - je mehrere branches  - Verzeichnisse
                    trino ways
            -->


            <div class="columns">
                <div class="column">
                    <p>
                        A simple <strong>organization</strong> of this stack is to have a single lakeFS instance for all teams.
                        This is the recommended organization for an exploratory data mesh approach, while things are small and simple.
                        In this, each team works in its own lakeFS repository, but all teams share one database connected with trino.
                        The teams can work in their own schemas, but these can not be access controlled to the other teams.
                        <br/><br/>
                        While this is a good starting point, it is likely that more access management will be needed in a production environment.
                        Therefore, this solution can be adjusted to an advanced approach, where each team works in its own lakeFS instance.
                        That way the access for other teams can be regulated through the lakeFS access control.
                    </p>
                    <p> <!-- ? -->
                        Additionally there are more instances of access management (MinIO, cloud provider), that can be configured if more levels of isolation are needed.
                    </p>
                </div>

                <div class="column">
                    <figure class="image">
                        <a href="../images/lakefs_lakeFS_access_management.png" class="glightbox">
                            <img src="../images/lakefs_lakeFS_access_management.png" alt="organization picture">
                        </a>
                    </figure>
                </div>
            </div>

            <!-- metadata tracking - visualizing data dependencies -->

            <div class="columns">
                <div class="column">
                    <p>
                        Data products retrieve data from source systems or from other data products, perform transformations and analytical processing and provide access to the results.
                        Tools for metadata tracking do support logging the corresponding metadata for each of these steps. Thus, they help to retrace and visualize the data flow and the dependencies between incoming and outgoing data.
                        Thereby they are using the visual <strong>data lineage graph</strong> to further support inspecting the processed data.
                        <br/>
                        We typically use <a href="https://marquezproject.github.io/marquez/">Marquez</a>, the reference implementation of the <a href="https://openlineage.io/">Openlineage Standard</a>, for metadata tracking.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/lakefs_datalineage_graph.png" class="glightbox">
                            <img src="../images/lakefs_datalineage_graph.png" alt="screenshot marquez lineage graph">
                        </a>
                    </figure>
                </div>
            </div>

            <!-- dashboard -->

            <div class="columns">
                <div class="column">
                    <p>
                        To create dashboards and visualization graphs, this tech stack provides <strong>multiple options to integrate packages or frameworks</strong>, which also allows to use frameworks that are already used in a current solution.
                        <br/>
                        In general, within jupyter notebooks, packages like Apache Zeppelin or matplotlib can be used to create data visualization diagrams. Also, through the JDBC endpoints
                        other tools can access the data products (or can be used within data products). Examples of those are Apache Superset, PowerBI, Tableau, Looker, and Sisense.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/lakeFS_jupyter_plot.png" class="glightbox">
                            <img src="../images/lakeFS_jupyter_plot.png" alt="screenshot of a visual demo graph in jupyter notebook">
                        </a>
                    </figure>
                </div>
            </div>

            <!-- ease of monitoring integration -->

            <div class="columns">
                <div class="column">
                    <p>
                        The tech stack can easily be integrated with modern <strong>monitoring</strong> tools.
                        <br/>
                        Therefore lakeFS as well as MinIO are offering a <a href="https://prometheus.io">Prometheus</a> integration for monitoring purposes.
                        Jupyter notebooks also have a variety of monitoring options. As always with jupyter notebooks, there is the option of implementing a monitoring graph on your own. Still, there are extensions like the <a href="https://github.com/jupyter-server/jupyter-resource-usage">jupyter resource usage</a>, which adds the current total memory usage of jupyter notebooks to the main toolbar.
                        <br/>
                        Additionally, trino offers an interface that provides information about queries. In this cluster overview you can track, which queries were ran, are still running, queued or blocked together with performance and workload measurements, like active workers, running drivers, reserved memory,
                        rows and bytes/sec, and worker parallelism. Furthermore, there is a list about every query, which can be inspected, sorted and searched through.
                    </p>
                </div>
                <div class="column">
                    <figure class="image">
                        <a href="../images/lakeFS_trino_overview.png" class="glightbox">
                            <img src="../images/lakeFS_trino_overview.png" alt="trino overview, maybe more">
                        </a>
                    </figure>
                </div>
            </div>

            <div>
                This stack is a powerful and highly flexible tech stack with a wide variety of integration possibilities.
                Of course, the integration of the different components needed for this tech stack has to be done by the data platform team.
                <br/> <!-- completely ? -->
                All in all, this stack is completely open source and, at least in a local environment, free of charge, which makes it a good solution to try out, when setting up a data mesh.
                Additionally, the customizability and flexibility of this tech stack allows to stick with programms and frameworks, which are already in use.
            </div>

            <h5 style="margin-top:1cm;">References</h5>
            <ul>
                <li><a href="https://docs.min.io">Official MinIO documentation</a></li>
                <li><a href="https://docs.lakefs.io">Official lakeFS documentation</a></li>
                <li><a href="https://trino.io/docs/current/">Official trino documentation</a></li>
                <li><a href="https://lakefs.io/category/integrations/">Various lakeFS blogposts to integration of lakeFS with MinIO and Trino</a></li>
                <li><a href="https://prometheus.io">Prometheus website</a></li>
                <li><a href="https://openlineage.io">Openlineage website</a></li>
                <li><a href="https://marquezproject.github.io/marquez/quickstart.html">Marquez github page</a></li>
                <li><a href="https://jupyter.org">Jupyter website</a></li>
                <li><a href="https://dbeaver.io">DBeaver website</a></li>
                <li><a href="https://zeppelin.apache.org">Official Apache Zeppelin documentation</a></li>
                <li><a href="https://matplotlib.org/stable/">Official matplotlib documentation</a></li>
                <li><a href="https://superset.apache.org">Official Apache Superset documentation</a></li>
                <li><a href="https://pandio.com">Official Pandio website</a></li>
            </ul>

        </div>
    </section>

</div>

<footer class="footer">
    <div class="content has-text-centered">
        <p>
            <a href="https://www.innoq.com">
                <img src="/images/supported-by-innoq--petrol-apricot.svg" alt="Supported by INNOQ" class="footer-logo" width="180" />
            </a>
        </p>
        <p>
            <a href="https://www.innoq.com/en/impressum/">Legal Notice</a>
            &nbsp
            <a href="https://www.innoq.com/en/datenschutz/">Privacy</a>
        </p>
    </div>
</footer>

<script src="/js/navigation.js"></script>

<script async defer src="https://scripts.simpleanalyticscdn.com/latest.js"></script>
<noscript><img src="https://queue.simpleanalyticscdn.com/noscript.gif" alt="" referrerpolicy="no-referrer-when-downgrade" /></noscript>

<link rel="stylesheet" href="/css/glightbox.css" />
<script src="/js/glightbox.js"></script>
<script type="text/javascript">
  const lightbox = GLightbox({});
</script>


<script src="/js/anchor.min.js"></script>
<script>anchors.add();</script>
</body>

</html>
